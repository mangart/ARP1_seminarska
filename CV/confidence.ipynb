{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-05T08:02:21.156633Z","iopub.execute_input":"2023-01-05T08:02:21.157101Z","iopub.status.idle":"2023-01-05T08:02:21.163723Z","shell.execute_reply.started":"2023-01-05T08:02:21.157045Z","shell.execute_reply":"2023-01-05T08:02:21.161800Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow\n!pip install tflite_support\n!pip install flatbuffers","metadata":{"execution":{"iopub.status.busy":"2023-01-05T08:02:21.168826Z","iopub.execute_input":"2023-01-05T08:02:21.169208Z","iopub.status.idle":"2023-01-05T08:03:14.156093Z","shell.execute_reply.started":"2023-01-05T08:02:21.169161Z","shell.execute_reply":"2023-01-05T08:03:14.154918Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (2.6.4)\nCollecting numpy~=1.19.2\n  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting flatbuffers~=1.12.0\n  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\nCollecting h5py~=3.1.0\n  Downloading h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: clang~=5.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (5.0)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.2)\nRequirement already satisfied: tensorboard<2.7,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.6.0)\nRequirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.15.0)\nRequirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.12.1)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.19.4)\nRequirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.6.0)\nCollecting typing-extensions<3.11,>=3.7\n  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\nRequirement already satisfied: grpcio<2.0,>=1.37.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.47.0)\nRequirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.15.0)\nRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\nRequirement already satisfied: keras<2.7,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.6.0)\nRequirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.35.0)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.6)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.7)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.28.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.2.2)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (59.8.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.8)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.7)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.1)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.13.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2022.9.24)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.13)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.1.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow) (2.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.8.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.2.0)\nInstalling collected packages: typing-extensions, flatbuffers, numpy, h5py\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.1.1\n    Uninstalling typing_extensions-4.1.1:\n      Successfully uninstalled typing_extensions-4.1.1\n  Attempting uninstall: flatbuffers\n    Found existing installation: flatbuffers 23.1.4\n    Uninstalling flatbuffers-23.1.4:\n      Successfully uninstalled flatbuffers-23.1.4\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.21.6\n    Uninstalling numpy-1.21.6:\n      Successfully uninstalled numpy-1.21.6\n  Attempting uninstall: h5py\n    Found existing installation: h5py 3.7.0\n    Uninstalling h5py-3.7.0:\n      Successfully uninstalled h5py-3.7.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\nbeatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\nxarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\ntfx-bsl 1.9.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.52.0 which is incompatible.\ntfx-bsl 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntfx-bsl 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\ntflite-support 0.4.3 requires flatbuffers>=2.0, but you have flatbuffers 1.12 which is incompatible.\ntflite-support 0.4.3 requires numpy>=1.20.0, but you have numpy 1.19.5 which is incompatible.\ntensorflow-transform 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\ntensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.6.4 which is incompatible.\nrich 12.6.0 requires typing-extensions<5.0,>=4.0.0; python_version < \"3.9\", but you have typing-extensions 3.10.0.2 which is incompatible.\npytorch-lightning 1.8.3.post1 requires typing-extensions>=4.0.0, but you have typing-extensions 3.10.0.2 which is incompatible.\npdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.5.3 which is incompatible.\npandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\nortools 9.5.2237 requires protobuf>=4.21.5, but you have protobuf 3.19.4 which is incompatible.\nnnabla 1.31.0 requires numpy>=1.20.0, but you have numpy 1.19.5 which is incompatible.\njaxlib 0.3.25 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\njax 0.3.25 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\nflax 0.6.2 requires typing-extensions>=4.1.1, but you have typing-extensions 3.10.0.2 which is incompatible.\nflake8 5.0.4 requires importlib-metadata<4.3,>=1.1.0; python_version < \"3.8\", but you have importlib-metadata 4.13.0 which is incompatible.\nfeaturetools 1.11.1 requires numpy>=1.21.0, but you have numpy 1.19.5 which is incompatible.\ncmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\napache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\napache-beam 2.40.0 requires pyarrow<8.0.0,>=0.15.1, but you have pyarrow 8.0.0 which is incompatible.\nallennlp 2.10.1 requires h5py>=3.6.0, but you have h5py 3.1.0 which is incompatible.\nallennlp 2.10.1 requires numpy>=1.21.4, but you have numpy 1.19.5 which is incompatible.\naioitertools 0.11.0 requires typing_extensions>=4.0; python_version < \"3.10\", but you have typing-extensions 3.10.0.2 which is incompatible.\naiobotocore 2.4.1 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.29.23 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed flatbuffers-1.12 h5py-3.1.0 numpy-1.19.5 typing-extensions-3.10.0.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: tflite_support in /opt/conda/lib/python3.7/site-packages (0.4.3)\nRequirement already satisfied: pybind11>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from tflite_support) (2.10.1)\nRequirement already satisfied: protobuf<4,>=3.18.0 in /opt/conda/lib/python3.7/site-packages (from tflite_support) (3.19.4)\nCollecting flatbuffers>=2.0\n  Using cached flatbuffers-23.1.4-py2.py3-none-any.whl (26 kB)\nRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tflite_support) (0.15.0)\nRequirement already satisfied: sounddevice>=0.4.4 in /opt/conda/lib/python3.7/site-packages (from tflite_support) (0.4.5)\nCollecting numpy>=1.20.0\n  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py>=0.7.0->tflite_support) (1.15.0)\nRequirement already satisfied: CFFI>=1.0 in /opt/conda/lib/python3.7/site-packages (from sounddevice>=0.4.4->tflite_support) (1.15.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite_support) (2.21)\nInstalling collected packages: flatbuffers, numpy\n  Attempting uninstall: flatbuffers\n    Found existing installation: flatbuffers 1.12\n    Uninstalling flatbuffers-1.12:\n      Successfully uninstalled flatbuffers-1.12\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.19.5\n    Uninstalling numpy-1.19.5:\n      Successfully uninstalled numpy-1.19.5\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-io 0.21.0 requires tensorflow-io-gcs-filesystem==0.21.0, which is not installed.\nbeatrix-jupyterlab 3.1.7 requires google-cloud-bigquery-storage, which is not installed.\ntfx-bsl 1.9.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.52.0 which is incompatible.\ntfx-bsl 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntfx-bsl 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<3,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\ntensorflow 2.6.4 requires flatbuffers~=1.12.0, but you have flatbuffers 23.1.4 which is incompatible.\ntensorflow 2.6.4 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\ntensorflow-transform 1.9.0 requires pyarrow<6,>=1, but you have pyarrow 8.0.0 which is incompatible.\ntensorflow-transform 1.9.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,<2.10,>=1.15.5, but you have tensorflow 2.6.4 which is incompatible.\ntensorflow-serving-api 2.9.0 requires tensorflow<3,>=2.9.0, but you have tensorflow 2.6.4 which is incompatible.\npytorch-lightning 1.8.3.post1 requires typing-extensions>=4.0.0, but you have typing-extensions 3.10.0.2 which is incompatible.\npdpbox 0.2.1 requires matplotlib==3.1.1, but you have matplotlib 3.5.3 which is incompatible.\npandas-profiling 3.1.0 requires markupsafe~=2.0.1, but you have markupsafe 2.1.1 which is incompatible.\nortools 9.5.2237 requires protobuf>=4.21.5, but you have protobuf 3.19.4 which is incompatible.\nflax 0.6.2 requires typing-extensions>=4.1.1, but you have typing-extensions 3.10.0.2 which is incompatible.\napache-beam 2.40.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\napache-beam 2.40.0 requires pyarrow<8.0.0,>=0.15.1, but you have pyarrow 8.0.0 which is incompatible.\nallennlp 2.10.1 requires h5py>=3.6.0, but you have h5py 3.1.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed flatbuffers-23.1.4 numpy-1.21.6\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.7/site-packages (23.1.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport os\nimport json\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report,confusion_matrix\n\n\nfrom tflite_support import metadata_schema_py_generated as _metadata_fb\nfrom tflite_support import metadata as _metadata\nimport flatbuffers","metadata":{"execution":{"iopub.status.busy":"2023-01-05T08:03:14.158015Z","iopub.execute_input":"2023-01-05T08:03:14.158312Z","iopub.status.idle":"2023-01-05T08:03:14.166892Z","shell.execute_reply.started":"2023-01-05T08:03:14.158284Z","shell.execute_reply":"2023-01-05T08:03:14.165846Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"IMAGES_PATH = \"../input/citypersondata/leftImg8bit_trainvaltest/leftImg8bit\"\nANNOTS_PATH = \"../input/citypersondata/gtBboxCityPersonsWithDangerLevel/gtBboxCityPersonsWithDangerLevel\"\nBASE_OUTPUT = \"output\"\n\nTRAIN_FILENAMES = \"../input/citypersondata-annot/train.txt\"\nTEST_FILENAMES = \"../input/citypersondata-annot/test.txt\"\nVAL_FILENAMES = \"../input/citypersondata-annot/val.txt\"\n\nNUM_CLASSES = 3\nOUTPUT_CLASSES = 4 #classes + background\n\nINIT_LR = 1e-4\nNUM_EPOCHS = 1\nBATCH_SIZE = 16\nBUFFER_SIZE = 40\n\nIMG_H = 512#224#512 #384 #360\nIMG_W = 512 #224 #512 #512 #480","metadata":{"execution":{"iopub.status.busy":"2023-01-05T08:03:14.168141Z","iopub.execute_input":"2023-01-05T08:03:14.168404Z","iopub.status.idle":"2023-01-05T08:03:14.178757Z","shell.execute_reply.started":"2023-01-05T08:03:14.168378Z","shell.execute_reply":"2023-01-05T08:03:14.177917Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def getClassFromJson(json_path):\n    json_f = open(json_path)\n    data = json.load(json_f)\n    objects = data[\"objects\"]\n    highest_num = 0\n    for o in objects:\n        danger_level = None\n        if \"danger_level\" in o:\n            danger_level = int(o[\"danger_level\"])\n        else:\n            danger_level = int(o[\"my_label\"])\n        \n        \n        if highest_num < danger_level:\n            highest_num = danger_level\n        if highest_num == 3:\n            break\n    return highest_num","metadata":{"execution":{"iopub.status.busy":"2023-01-05T08:03:14.181145Z","iopub.execute_input":"2023-01-05T08:03:14.181605Z","iopub.status.idle":"2023-01-05T08:03:14.192863Z","shell.execute_reply.started":"2023-01-05T08:03:14.181566Z","shell.execute_reply":"2023-01-05T08:03:14.191931Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def returnNamesLabels(filename):\n    trainDataNames = []\n    trainDataLabels = []\n    f = open(filename, \"r\")\n    for r in f:\n        r = r.split(\",\") #image path, annotation path\n        img_path = r[0]\n        annot_path = r[1][:-1] #without \\n\n        class_num = getClassFromJson(annot_path)\n        trainDataNames.append(img_path)\n        trainDataLabels.append(class_num)\n    f.close()\n    return trainDataNames, trainDataLabels","metadata":{"execution":{"iopub.status.busy":"2023-01-05T08:03:14.194447Z","iopub.execute_input":"2023-01-05T08:03:14.194872Z","iopub.status.idle":"2023-01-05T08:03:14.203516Z","shell.execute_reply.started":"2023-01-05T08:03:14.194833Z","shell.execute_reply":"2023-01-05T08:03:14.202655Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"trainDataNames, trainDataLabels = returnNamesLabels(TRAIN_FILENAMES)\nvalDataNames, valDataLabels = returnNamesLabels(VAL_FILENAMES)\ntestDataNames, testDataLabels = returnNamesLabels(TEST_FILENAMES)\n\nallDataNames = trainDataNames + valDataNames + testDataNames\nallDataLabels = trainDataLabels + valDataLabels + testDataLabels","metadata":{"execution":{"iopub.status.busy":"2023-01-05T08:03:14.204525Z","iopub.execute_input":"2023-01-05T08:03:14.204926Z","iopub.status.idle":"2023-01-05T08:03:16.541860Z","shell.execute_reply.started":"2023-01-05T08:03:14.204884Z","shell.execute_reply":"2023-01-05T08:03:16.540673Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(allDataNames, allDataLabels, test_size=0.1438, random_state=42, shuffle=True, stratify=allDataLabels)\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.122689, random_state=42, shuffle=True, stratify=y_train)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T08:03:16.543463Z","iopub.execute_input":"2023-01-05T08:03:16.543876Z","iopub.status.idle":"2023-01-05T08:03:16.560010Z","shell.execute_reply.started":"2023-01-05T08:03:16.543833Z","shell.execute_reply":"2023-01-05T08:03:16.558747Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(len(y_test))\nprint(len(y_train))\nprint(len(y_val))\n\nSTEPS_PER_EPOCH = len(y_train) // BATCH_SIZE","metadata":{"execution":{"iopub.status.busy":"2023-01-05T08:03:16.561865Z","iopub.execute_input":"2023-01-05T08:03:16.563047Z","iopub.status.idle":"2023-01-05T08:03:16.570377Z","shell.execute_reply.started":"2023-01-05T08:03:16.562998Z","shell.execute_reply":"2023-01-05T08:03:16.569248Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"500\n2610\n365\n","output_type":"stream"}]},{"cell_type":"code","source":"def normalize(input_image, label):\n    input_image = tf.cast(input_image, tf.float32) / 255.0\n    return input_image, label\n\ndef read_image(image_path, h, w):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_png(image, channels=3)\n    return tf.image.resize(image, [h, w])\n\ndef load_image(image_path, label, imageH, imageW):\n    input_image = read_image(image_path, imageH, imageW)\n    input_image, label = normalize(input_image, label)\n    return input_image, label","metadata":{"execution":{"iopub.status.busy":"2023-01-05T08:03:16.572251Z","iopub.execute_input":"2023-01-05T08:03:16.572661Z","iopub.status.idle":"2023-01-05T08:03:16.581325Z","shell.execute_reply.started":"2023-01-05T08:03:16.572621Z","shell.execute_reply":"2023-01-05T08:03:16.580621Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class Augment(tf.keras.layers.Layer):\n    def __init__(self, seed=42):\n        super().__init__()\n        # both use the same seed, so they'll make the same random changes.\n        self.augment_inputs = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n\n    def call(self, inputs, labels):\n        inputs = self.augment_inputs(inputs)\n        return inputs, labels","metadata":{"execution":{"iopub.status.busy":"2023-01-05T08:03:16.585085Z","iopub.execute_input":"2023-01-05T08:03:16.585966Z","iopub.status.idle":"2023-01-05T08:03:16.592208Z","shell.execute_reply.started":"2023-01-05T08:03:16.585929Z","shell.execute_reply":"2023-01-05T08:03:16.591147Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"interpreter = tf.lite.Interpreter(model_path=\"/kaggle/input/mobilenet/mobilenet_06_12_9pm.tflite\")\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\ninterpreter.allocate_tensors()","metadata":{"execution":{"iopub.status.busy":"2023-01-05T08:03:16.593375Z","iopub.execute_input":"2023-01-05T08:03:16.593831Z","iopub.status.idle":"2023-01-05T08:03:16.606199Z","shell.execute_reply.started":"2023-01-05T08:03:16.593803Z","shell.execute_reply":"2023-01-05T08:03:16.604775Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"test_images = []\nfor img_path in X_test:\n    img_arr = cv2.imread(img_path)[...,::-1]\n    resized_arr = cv2.resize(img_arr, (IMG_H, IMG_W))\n    test_images.append(resized_arr)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T08:03:16.607628Z","iopub.execute_input":"2023-01-05T08:03:16.608790Z","iopub.status.idle":"2023-01-05T08:04:14.265619Z","shell.execute_reply.started":"2023-01-05T08:03:16.608734Z","shell.execute_reply":"2023-01-05T08:04:14.264622Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"test_images = np.array(test_images, dtype=\"float32\") / 255\ntest_images.reshape(-1, IMG_H, IMG_W, 1)\nzzzzzzz = 0","metadata":{"execution":{"iopub.status.busy":"2023-01-05T08:04:14.267039Z","iopub.execute_input":"2023-01-05T08:04:14.268119Z","iopub.status.idle":"2023-01-05T08:04:14.960900Z","shell.execute_reply.started":"2023-01-05T08:04:14.268032Z","shell.execute_reply":"2023-01-05T08:04:14.959489Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#predictions = np.argmax(interpreter.predict(test_images, batch_size=BATCH_SIZE), axis=-1)\ncount_true = 0\ncount_false = 0\nfor i, new_img in enumerate(test_images): \n    interpreter.set_tensor(input_details[0]['index'], [new_img])\n    interpreter.invoke()\n    output_data = interpreter.get_tensor(output_details[0]['index'])\n    prediction = tf.nn.softmax(output_data[0])\n    \n    #print(prediction, np.max(prediction), np.argmax(prediction), y_test[i], y_test[i]==np.argmax(prediction))\n    if np.max(prediction) > 0.70:\n        print(np.max(prediction), np.argmax(prediction), y_test[i], y_test[i]==np.argmax(prediction))\n        if y_test[i]==np.argmax(prediction):\n            count_true += 1\n        else:\n            count_false += 1","metadata":{"execution":{"iopub.status.busy":"2023-01-05T08:04:14.962631Z","iopub.execute_input":"2023-01-05T08:04:14.963814Z","iopub.status.idle":"2023-01-05T08:05:03.247471Z","shell.execute_reply.started":"2023-01-05T08:04:14.963773Z","shell.execute_reply":"2023-01-05T08:05:03.244587Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"2023-01-05 08:04:15.205110: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"},{"name":"stdout","text":"0.79609066 1 1 True\n0.7107028 1 2 False\n0.72960496 1 1 True\n0.81412387 1 1 True\n0.77122426 1 1 True\n0.75170773 1 1 True\n0.7595215 1 1 True\n0.71219057 1 1 True\n0.9531153 3 3 True\n0.7658435 1 1 True\n0.7267275 1 1 True\n0.73559546 1 1 True\n0.745762 1 0 False\n0.7185498 1 2 False\n0.76082873 1 1 True\n0.7344368 1 0 False\n0.7367854 1 1 True\n0.7336365 1 1 True\n0.82420033 1 1 True\n0.71700114 1 1 True\n0.7235215 1 1 True\n0.893096 3 2 False\n0.73222274 1 1 True\n0.7929529 1 1 True\n0.75424594 1 1 True\n0.73682064 1 2 False\n0.8377285 1 1 True\n0.7998611 1 2 False\n0.7682537 1 1 True\n0.75847846 1 1 True\n0.8380248 1 1 True\n0.7909627 1 1 True\n0.74096704 1 2 False\n0.75234073 1 1 True\n0.7900589 1 2 False\n0.7212747 1 1 True\n0.94491494 3 3 True\n0.8415304 1 2 False\n0.73555994 1 1 True\n0.770071 1 0 False\n0.70557564 1 1 True\n0.744934 1 0 False\n0.7625135 1 0 False\n0.7237138 1 1 True\n0.81530166 3 3 True\n0.7471345 1 0 False\n0.8546185 3 3 True\n0.7200756 1 1 True\n0.7811946 1 1 True\n0.765117 1 0 False\n0.7030947 1 1 True\n0.840227 1 1 True\n0.7772522 1 1 True\n0.7776458 1 0 False\n0.7984927 1 1 True\n0.8098693 1 1 True\n0.75746787 1 1 True\n0.76489747 1 0 False\n0.9500445 3 3 True\n0.8375962 1 1 True\n0.741903 1 1 True\n0.75923103 1 1 True\n0.8013316 1 1 True\n0.70308477 1 2 False\n0.7428717 1 1 True\n0.80003065 1 1 True\n0.7412612 3 3 True\n0.79316926 1 1 True\n0.7572788 1 1 True\n0.7478292 1 1 True\n0.842555 1 1 True\n0.731621 1 1 True\n0.7733206 1 1 True\n0.7471161 1 1 True\n0.819214 1 1 True\n0.8131706 1 1 True\n0.9767122 3 3 True\n0.7227757 1 2 False\n0.76720047 1 1 True\n0.8095248 1 1 True\n0.7629473 1 1 True\n0.7644931 1 1 True\n0.79369384 1 1 True\n0.7764692 1 0 False\n0.7231371 1 1 True\n0.81874686 1 1 True\n0.8166599 1 1 True\n0.7994048 1 1 True\n0.75873053 1 1 True\n0.7590189 1 0 False\n0.82013804 1 1 True\n0.7258808 1 2 False\n0.7051062 1 1 True\n0.76174515 1 1 True\n0.8275361 1 1 True\n0.7723065 1 1 True\n0.74104077 1 3 False\n0.7673018 1 1 True\n0.97611326 3 3 True\n0.86650705 1 1 True\n0.70552635 1 1 True\n0.8099597 1 1 True\n0.8079311 1 1 True\n0.7456719 1 2 False\n0.80773157 1 1 True\n0.7626144 1 1 True\n0.728709 1 2 False\n0.75375116 1 1 True\n0.85908073 3 3 True\n0.77218384 1 1 True\n0.74686724 1 1 True\n0.7376051 1 0 False\n0.73476386 1 1 True\n0.7387336 1 1 True\n0.73892367 1 2 False\n0.7435478 1 1 True\n0.75655216 1 1 True\n0.8558394 1 1 True\n0.8164939 1 1 True\n0.7563159 1 0 False\n0.7497317 3 2 False\n0.74820644 1 1 True\n0.7908352 1 1 True\n0.75653297 1 1 True\n0.7239661 1 2 False\n0.8391034 1 1 True\n0.79607916 1 1 True\n0.8637719 3 3 True\n0.728418 1 0 False\n0.70649284 1 1 True\n0.7636364 1 1 True\n0.96923494 3 3 True\n0.9530609 3 3 True\n0.8063177 1 0 False\n0.78706264 1 1 True\n0.76208496 1 0 False\n0.78738225 1 1 True\n0.7376912 1 2 False\n0.8129108 1 1 True\n0.8172176 1 1 True\n0.75730425 1 2 False\n0.74317324 1 1 True\n0.73378825 1 1 True\n0.7259377 1 3 False\n0.76375866 1 1 True\n0.7484256 1 1 True\n0.85201854 1 0 False\n0.72390306 1 1 True\n0.7557909 1 1 True\n0.7896225 1 1 True\n0.96287054 3 3 True\n0.7802954 1 1 True\n0.70170856 1 0 False\n0.80314356 1 1 True\n0.7264312 1 1 True\n0.7050926 1 1 True\n0.72445273 1 0 False\n0.77117854 1 1 True\n0.8057304 1 1 True\n0.75694793 1 1 True\n0.7063297 1 1 True\n0.85527706 3 3 True\n0.7858244 1 1 True\n0.7120698 1 0 False\n0.7115733 1 1 True\n0.84238964 1 1 True\n0.84628356 1 1 True\n0.71545875 3 3 True\n0.81375414 1 2 False\n0.7186493 1 2 False\n0.78079987 1 1 True\n0.81987345 1 1 True\n0.706115 1 1 True\n0.7866915 1 0 False\n0.7623501 3 2 False\n0.7646589 1 1 True\n0.78777736 1 2 False\n0.7586707 1 1 True\n0.82251644 3 3 True\n0.71966654 1 1 True\n0.7551213 1 0 False\n0.7530118 1 1 True\n0.8333016 1 1 True\n0.7577868 1 0 False\n0.74124855 1 2 False\n0.8420224 1 1 True\n0.7950714 1 1 True\n0.75251377 1 1 True\n0.7973961 1 1 True\n0.73742265 1 1 True\n0.8257344 1 1 True\n0.82031786 1 1 True\n0.7541888 1 1 True\n0.76856554 1 1 True\n0.719957 1 1 True\n0.80116516 1 1 True\n0.8083247 1 1 True\n0.75491154 1 1 True\n0.829136 1 1 True\n0.82919395 1 1 True\n0.75863254 1 1 True\n0.77662027 1 1 True\n0.7925336 1 1 True\n0.8717007 1 1 True\n0.75841385 1 1 True\n0.76863235 1 1 True\n0.72579914 1 1 True\n0.82317126 1 2 False\n0.77013224 1 1 True\n0.7143077 1 0 False\n0.7773941 1 0 False\n0.8147528 1 1 True\n0.8924919 1 1 True\n0.82514894 1 1 True\n0.7310864 1 1 True\n0.8859571 3 3 True\n0.7340793 1 1 True\n0.7854374 1 1 True\n0.78620774 1 1 True\n0.7905495 1 1 True\n0.74753606 1 1 True\n0.7025982 1 1 True\n0.7910402 1 1 True\n0.79693675 1 1 True\n0.780789 1 0 False\n0.874208 1 1 True\n0.72964674 1 1 True\n0.7556885 3 3 True\n0.71712804 1 1 True\n0.75913596 1 1 True\n0.7372796 1 2 False\n0.79392874 1 1 True\n0.75095516 1 1 True\n0.7633863 1 1 True\n0.7864344 1 0 False\n0.7385187 1 0 False\n0.8584716 1 1 True\n0.7367994 1 2 False\n0.78719735 1 1 True\n0.7944114 3 3 True\n0.8019842 1 2 False\n0.82990134 1 1 True\n0.749256 1 1 True\n0.79464674 1 1 True\n0.7224138 1 1 True\n0.7819933 1 0 False\n","output_type":"stream"}]},{"cell_type":"code","source":"count_true/(count_true+count_false)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T08:05:03.248409Z","iopub.execute_input":"2023-01-05T08:05:03.249050Z","iopub.status.idle":"2023-01-05T08:05:03.259612Z","shell.execute_reply.started":"2023-01-05T08:05:03.249012Z","shell.execute_reply":"2023-01-05T08:05:03.258364Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"0.7642276422764228"},"metadata":{}}]},{"cell_type":"code","source":"(count_true+count_false)/len(test_images)","metadata":{"execution":{"iopub.status.busy":"2023-01-05T08:05:03.260879Z","iopub.execute_input":"2023-01-05T08:05:03.261236Z","iopub.status.idle":"2023-01-05T08:05:03.270295Z","shell.execute_reply.started":"2023-01-05T08:05:03.261204Z","shell.execute_reply":"2023-01-05T08:05:03.269218Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"0.492"},"metadata":{}}]}]}